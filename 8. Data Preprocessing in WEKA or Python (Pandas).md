# 8. Data Preprocessing in WEKA or Python (Pandas)8. Data Preprocessing in WEKA or Python (Pandas)

Load a dataset (e.g., Titanic or Iris), handle 

> Load a dataset (e.g., Titanic or Iris), handle missing values, normalize data, and discretize continuous attributes.missing values, normalize data, and discretize 

continuous attributes.

---



## Data Preprocessing in WEKA

Data Preprocessing in WEKA

WEKA has a GUI called Explorer, which makes preprocessing simple.WEKA has a GUI called Explorer, which makes preprocessing simple.



### Steps:Steps:



#### 1. Load DatasetLoad Dataset



- Open WEKA → Explorer → "Preprocess" tab.Open WEKA → Explorer → "Preprocess" tab.

- Load a dataset (e.g., `iris.arff` or `titanic.arff`).

Load a dataset (e.g., iris.arff or titanic.arff).

#### 2. Handle Missing Values

Handle Missing Values

- Go to **Filter → Unsupervised → Attribute → ReplaceMissingValues**.

- Apply → missing values are replaced with mean (numeric) or mode (categorical).Go to Filter → Unsupervised → Attribute → ReplaceMissingValues.



#### 3. Normalize DataApply → missing values are replaced with mean (numeric) or mode (categorical).



- **Filter → Unsupervised → Attribute → Normalize**.Normalize Data

- This scales values between 0 and 1.

Filter → Unsupervised → Attribute → Normalize.

#### 4. Discretize Continuous Attributes

This scales values between 0 and 1.

- **Filter → Unsupervised → Attribute → Discretize**.

- Choose number of bins (e.g., 5 bins).Discretize Continuous Attributes

- This converts continuous attributes into categorical intervals.

Filter → Unsupervised → Attribute → Discretize.

✅ After preprocessing, you can save the processed dataset in `.arff` or `.csv`.

Choose number of bins (e.g., 5 bins).

---

This converts continuous attributes into categorical intervals.

## Data Preprocessing in Python (Pandas)

✅ After preprocessing, you can save the processed dataset in .arff or .csv.

### 1. Load Dataset


```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import KBinsDiscretizer

# Load Titanic dataset
df = pd.read_csv('titanic.csv')
print(df.head())
print(df.info())
```

### 2. Handle Missing Values

```python
# Check missing values
print(df.isnull().sum())

# Fill missing numeric values with mean
df['Age'].fillna(df['Age'].mean(), inplace=True)

# Fill missing categorical values with mode
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# Drop rows with too many missing values
df.dropna(subset=['Cabin'], inplace=True)
```

### 3. Normalize Data

```python
# Normalize numeric columns to [0, 1] range
scaler = MinMaxScaler()
df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])
print(df[['Age', 'Fare']].head())
```

### 4. Discretize Continuous Attributes

```python
# Discretize Age into 5 bins
discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')
df['Age_binned'] = discretizer.fit_transform(df[['Age']])
print(df[['Age', 'Age_binned']].head())
```

### 5. Save Preprocessed Data

```python
df.to_csv('titanic_preprocessed.csv', index=False)
print("Preprocessed data saved!")
```

---

## Summary

| **Operation** | **WEKA** | **Python (Pandas)** |
|---------------|----------|-------------------|
| **Load Data** | GUI Explorer | `pd.read_csv()` |
| **Handle Missing** | ReplaceMissingValues filter | `fillna()`, `dropna()` |
| **Normalize** | Normalize filter | `MinMaxScaler` |
| **Discretize** | Discretize filter | `KBinsDiscretizer` |
